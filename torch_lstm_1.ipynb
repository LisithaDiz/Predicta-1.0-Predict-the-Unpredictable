{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: torch in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Ern2ZiHNW3mo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0WYvTHBaqk7",
        "outputId": "36e538a3-92a4-4e9b-9dcd-263718447e20"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\", force_remount=True)\n",
        "# cd \"/content/drive/MyDrive/Predicta/Competition\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Dk47Zau-W3mq"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('new_features_added_filled_nearest_neigb_min.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Apk-HwBW3mr",
        "outputId": "80b70d65-5c9e-4d24-ed12-86f7fdfd77cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['city_id', 'date', 'avg_temp_c', 'min_temp_c', 'max_temp_c',\n",
              "       'avg_wind_dir_deg', 'avg_wind_speed_kmh', 'city', 'day_of_week',\n",
              "       'day_of_year', 'month', 'temp_range'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "EnFMZ5ZLW3ms"
      },
      "outputs": [],
      "source": [
        "# Python\n",
        "selected_columns_to_exclude = ['date', 'city_id',\n",
        "                               'snow_depth_mm', 'day_of_week']\n",
        "features = [col for col in data.columns if col not in selected_columns_to_exclude]\n",
        "\n",
        "target = 'avg_temp_c'\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "# Python\n",
        "numerical_features = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMKDjT8rKows",
        "outputId": "f2dea009-0a72-4976-c65c-edf8390c9816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of records: 182338\n",
            "Number of records with at least one null value: 0\n"
          ]
        }
      ],
      "source": [
        "num_rows_with_nulls = data.isnull().any(axis=1).sum()\n",
        "print(f\"Number of records: {len(data)}\")\n",
        "print(f\"Number of records with at least one null value: {num_rows_with_nulls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DaIIBZhWW3mt",
        "outputId": "ac610aac-25af-4e02-d3fd-8f962e3c48ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city_id</th>\n",
              "      <th>date</th>\n",
              "      <th>avg_temp_c</th>\n",
              "      <th>min_temp_c</th>\n",
              "      <th>max_temp_c</th>\n",
              "      <th>avg_wind_dir_deg</th>\n",
              "      <th>avg_wind_speed_kmh</th>\n",
              "      <th>city</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>month</th>\n",
              "      <th>temp_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>-1.244652</td>\n",
              "      <td>-1.615164</td>\n",
              "      <td>-1.181246</td>\n",
              "      <td>-0.084152</td>\n",
              "      <td>-0.825328</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>-0.500611</td>\n",
              "      <td>-1.727467</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.840131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>-0.974157</td>\n",
              "      <td>-0.843364</td>\n",
              "      <td>-1.017647</td>\n",
              "      <td>-0.212386</td>\n",
              "      <td>-0.202979</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>-0.000590</td>\n",
              "      <td>-1.717983</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>-0.472820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>-1.144469</td>\n",
              "      <td>-1.284393</td>\n",
              "      <td>-0.950283</td>\n",
              "      <td>0.157519</td>\n",
              "      <td>-0.890838</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>0.499431</td>\n",
              "      <td>-1.708498</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.643188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>-1.144469</td>\n",
              "      <td>-1.083925</td>\n",
              "      <td>-1.017647</td>\n",
              "      <td>1.129135</td>\n",
              "      <td>0.009929</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>0.999452</td>\n",
              "      <td>-1.699014</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.052360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>-1.044286</td>\n",
              "      <td>-1.424720</td>\n",
              "      <td>-0.671204</td>\n",
              "      <td>0.225335</td>\n",
              "      <td>-1.021859</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>1.499473</td>\n",
              "      <td>-1.689529</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>1.584136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  city_id        date  avg_temp_c  min_temp_c  max_temp_c  avg_wind_dir_deg  \\\n",
              "0    C001  2014-01-01   -1.244652   -1.615164   -1.181246         -0.084152   \n",
              "1    C001  2014-01-02   -0.974157   -0.843364   -1.017647         -0.212386   \n",
              "2    C001  2014-01-03   -1.144469   -1.284393   -0.950283          0.157519   \n",
              "3    C001  2014-01-04   -1.144469   -1.083925   -1.017647          1.129135   \n",
              "4    C001  2014-01-05   -1.044286   -1.424720   -0.671204          0.225335   \n",
              "\n",
              "   avg_wind_speed_kmh      city  day_of_week  day_of_year     month  \\\n",
              "0           -0.825328 -1.729156    -0.500611    -1.727467 -1.601858   \n",
              "1           -0.202979 -1.729156    -0.000590    -1.717983 -1.601858   \n",
              "2           -0.890838 -1.729156     0.499431    -1.708498 -1.601858   \n",
              "3            0.009929 -1.729156     0.999452    -1.699014 -1.601858   \n",
              "4           -1.021859 -1.729156     1.499473    -1.689529 -1.601858   \n",
              "\n",
              "   temp_range  \n",
              "0    0.840131  \n",
              "1   -0.472820  \n",
              "2    0.643188  \n",
              "3    0.052360  \n",
              "4    1.584136  "
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(data[features].head())\n",
        "\n",
        "# data_filled = data.fillna(-1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Calculate the IQR\n",
        "# Q1 = data['avg_temp_c'].quantile(0.25)\n",
        "# Q3 = data['avg_temp_c'].quantile(0.75)\n",
        "# IQR = Q3 - Q1\n",
        "\n",
        "# # Define the lower and upper bounds for outliers\n",
        "# lower_bound = Q1 - 1.5 * IQR\n",
        "# upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# # Identify outliers\n",
        "# outliers = data[(data['avg_temp_c'] < lower_bound) | (data['avg_temp_c'] > upper_bound)]\n",
        "# print(\"Outliers in avg_temp_c:\")\n",
        "# print(outliers)\n",
        "# outliers.shape, data.shape\n",
        "# # Remove outliers\n",
        "# data_cleaned = data[(data['avg_temp_c'] >= lower_bound) & (data['avg_temp_c'] <= upper_bound)]\n",
        "\n",
        "# # Display the cleaned data\n",
        "# print(data_cleaned.head())\n",
        "# data  = data_cleaned "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "bmpLwNTnW3mt"
      },
      "outputs": [],
      "source": [
        "# Create sequences for each city\n",
        "def create_sequences(df, features, target, seq_length=30, pred_length=7):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(df) - seq_length - pred_length + 1):\n",
        "        X.append(df[features].iloc[i:i+seq_length].values)\n",
        "        y.append(df[target].iloc[i+seq_length:i+seq_length+pred_length].values)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# Split data by city and create sequences\n",
        "city_data = data.groupby('city_id')\n",
        "seq_length=30\n",
        "X_list = []\n",
        "y_list = []\n",
        "X_list_final = []\n",
        "last_dates = []\n",
        "for i, (_, group) in enumerate(city_data):\n",
        "    X, y = create_sequences(group, features, target, seq_length=seq_length)\n",
        "    X_list.append(X)\n",
        "    y_list.append(y)\n",
        "    X_last = group[features].iloc[-seq_length:].values\n",
        "    X_list_final.append(X_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--1L3KiSW3mt",
        "outputId": "d61252e2-c152-4e90-f808-b98fb1783565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "1790\n",
            "1790\n",
            "[1790, 1767, 1787, 1790, 1790, 1789, 1790, 1790, 1769, 1790, 1787, 1790, 1790, 1790, 1788, 1790, 1780, 1790, 1790, 1790, 1790, 1787, 1773, 1790, 1777, 1790, 1790, 1787, 1790, 1790, 1790, 1790, 1790, 1790, 1776, 1790, 1788, 1790, 1789, 1789, 1790, 1790, 1790, 1790, 1790, 1789, 1790, 1753, 1790, 1790, 1789, 1789, 1790, 1787, 1790, 1789, 1786, 1790, 1789, 1790, 1790, 1790, 1790, 1781, 1790, 1789, 1790, 1790, 1788, 1790, 1790, 1790, 1790, 1790, 1790, 1776, 1790, 1790, 1789, 1774, 1790, 1790, 1784, 1790, 1790, 1787, 1790, 1784, 1790, 1789, 1790, 1788, 1789, 1790, 1790, 1790, 1790, 1789, 1783, 1764]\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "print(len(X_list))\n",
        "print(len(y_list))\n",
        "print(len(X_list[0]))\n",
        "print(len(y_list[0]))\n",
        "lengths = [len(element) for element in X_list]\n",
        "print(lengths)\n",
        "print(len(X_list[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "PnTFuL0bW3mu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VBHveosW3mu",
        "outputId": "ec41d2d2-e55b-4dea-fab5-f03fb636e1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(178738, 30, 9)\n",
            "(100, 30, 9)\n"
          ]
        }
      ],
      "source": [
        "print(np.concatenate(X_list, axis=0).shape)\n",
        "print(np.array(X_list_final).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "JDBaBNUOIRtM"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "\n",
        "# Split into train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2)\n",
        "num_samples = X.shape[0]  # Number of samples in your dataset\n",
        "split_index = int(num_samples * (1 - 0.2))  # Calculate index for 80% of the data\n",
        "\n",
        "# Split the data at the calculated index\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "lueKAvApIUwL"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "Wc_SdQ70W3mu"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NBBTxb6W3mv",
        "outputId": "ca8d255a-01e0-4c21-e884-0a319eaa7b4a"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_predict_tensor = torch.tensor(X_list_final, dtype=torch.float32).to(device)\n",
        "predict_dataset = TensorDataset(X_predict_tensor)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yVgEQcW3mv",
        "outputId": "d2cccd31-7c0b-4996-ac0f-f8ed9e21dda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Inputs Shape: torch.Size([32, 30, 9]), Train Targets Shape: torch.Size([32, 7])\n",
            "Test Inputs Shape: torch.Size([32, 30, 9]), Test Targets Shape: torch.Size([32, 7])\n",
            "Predict Inputs Shape: torch.Size([1, 30, 9])\n"
          ]
        }
      ],
      "source": [
        "# For the train loader\n",
        "for i, (inputs, targets) in enumerate(train_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Train Inputs Shape: {inputs.shape}, Train Targets Shape: {targets.shape}')\n",
        "# For the test loader\n",
        "for i, (inputs, targets) in enumerate(test_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Test Inputs Shape: {inputs.shape}, Test Targets Shape: {targets.shape}')\n",
        "for i, (inputs,) in enumerate(predict_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Predict Inputs Shape: {inputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "p6ULpEUEW3mw"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layer_size, output_size, num_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size,\n",
        "                            num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout layer before the fully connected layer\n",
        "        self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.dropout(out[:, -1, :])  # Apply dropout to the output of the LSTM layer\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "O2U3rAfbW3mw"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, target in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        # Apply gradient clipping\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "RhQ7_r69W3mw"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, criterion, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "u0-P7fVBW3mw"
      },
      "outputs": [],
      "source": [
        "def model_fit(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs=25, patience=10, checkpoint=40):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_model(\n",
        "            model, criterion, optimizer, train_dataloader)\n",
        "        test_loss = evaluate_model(\n",
        "            model, criterion, test_dataloader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            best_test_loss = test_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if (epoch + 1) % checkpoint == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return model, train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "HXuaDH5PW3mx"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, test_losses, figsize=(6, 3)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "iv131aYXrVL3"
      },
      "outputs": [],
      "source": [
        "# Define model, loss function, and optimizer\n",
        "input_size = len(features)\n",
        "hidden_layer_size = 64\n",
        "output_size = 7\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "model = LSTMModel(input_size, hidden_layer_size,\n",
        "                  output_size, num_layers, dropout).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XQk6hwW3mx",
        "outputId": "04009817-fe37-4b23-c305-9d35f36d73af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25: Train Loss = 0.0861, Test Loss = 0.0716\n",
            "Epoch 10/25: Train Loss = 0.0850, Test Loss = 0.0710\n",
            "Epoch 15/25: Train Loss = 0.0845, Test Loss = 0.0737\n",
            "Epoch 20/25: Train Loss = 0.0842, Test Loss = 0.0721\n",
            "Early stopping triggered\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model, train_losses, test_losses = model_fit(\n",
        "    model, loss_function, optimizer, train_loader, test_loader, num_epochs=25, checkpoint=5, patience=10)\n",
        "plot_losses(train_losses, test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "o5q9j-y-W3mx"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "submission_df = pd.DataFrame(\n",
        "    columns=['submission_ID', 'city_id', 'date', \"avg_temp_c\"])\n",
        "# Initialize an non-empty DataFrame\n",
        "submission_df = pd.DataFrame(\n",
        "    {'submission_ID': [0], 'city_id': ['C000'], 'date': [datetime.strptime('2019-01-01', '%Y-%m-%d')], \"avg_temp_c\": [0.0]})\n",
        "\n",
        "# Initialize the submission ID\n",
        "submission_ID = 1\n",
        "date = datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
        "# Iterate over the list of sequences\n",
        "for i, (inputs,) in enumerate(predict_loader):\n",
        "    # Generate the city_id\n",
        "    city_id = 'C' + str(i+1).zfill(3)\n",
        "\n",
        "    # Use the model to predict the next 14 days\n",
        "    predictions = model(inputs)\n",
        "    predictions = predictions.detach().cpu().numpy().flatten()\n",
        "    # For each day in the prediction\n",
        "    for j in range(7):\n",
        "        # Append a new row to the DataFrame\n",
        "        new_entry = pd.DataFrame(\n",
        "            {'submission_ID': [submission_ID], 'city_id': [city_id], 'date': [date], \"avg_temp_c\": [predictions[j]]}, index=[0])\n",
        "        submission_df = pd.concat([submission_df, new_entry], ignore_index=True)\n",
        "        # Increment the submission ID\n",
        "        date += timedelta(days=1)\n",
        "        submission_ID += 1\n",
        "    date = datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
        "# Drop the initial row\n",
        "submission_df = submission_df.iloc[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RYLflxXW3mx",
        "outputId": "ee611904-01ad-4b39-cfdb-c0e317121bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     submission_ID city_id       date  avg_temp_c\n",
            "1                1    C001 2019-01-01   -0.870055\n",
            "2                2    C001 2019-01-02   -0.897859\n",
            "3                3    C001 2019-01-03   -0.897581\n",
            "4                4    C001 2019-01-04   -0.890186\n",
            "5                5    C001 2019-01-05   -0.904331\n",
            "..             ...     ...        ...         ...\n",
            "696            696    C100 2019-01-03    0.178875\n",
            "697            697    C100 2019-01-04    0.181128\n",
            "698            698    C100 2019-01-05    0.180842\n",
            "699            699    C100 2019-01-06    0.181141\n",
            "700            700    C100 2019-01-07    0.176811\n",
            "\n",
            "[700 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(submission_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "r7CCxHnDLbo3"
      },
      "outputs": [],
      "source": [
        "y_pred_original_scale_placeholder = np.zeros((submission_df.shape[0], 10))\n",
        "\n",
        "y_pred_original_scale_placeholder[:, 0] = submission_df['avg_temp_c'].values\n",
        "\n",
        "y_pred_original_scale = scaler.inverse_transform(y_pred_original_scale_placeholder)\n",
        "\n",
        "y_pred_original_scale = y_pred_original_scale[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pJDX4nVKoif",
        "outputId": "721c5d2c-4305-41fb-e4e7-341bdbfa4b53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1.03391221e+01,  1.00615879e+01,  1.00643651e+01,  1.01381749e+01,\n",
              "        9.99698630e+00,  9.81631998e+00,  9.88049260e+00,  1.44035582e+01,\n",
              "        1.44631640e+01,  1.45758413e+01,  1.46903690e+01,  1.46417575e+01,\n",
              "        1.45751378e+01,  1.46147307e+01,  2.66110327e+01,  2.65945226e+01,\n",
              "        2.64374666e+01,  2.62994676e+01,  2.62650838e+01,  2.62924852e+01,\n",
              "        2.61820374e+01, -2.14096265e-01, -5.86233854e-02,  4.30859342e-01,\n",
              "        7.99546832e-01,  7.55635463e-01,  5.70726509e-01,  7.77454903e-01,\n",
              "        2.46157694e+01,  2.45814732e+01,  2.44470058e+01,  2.43436226e+01,\n",
              "        2.43050236e+01,  2.43076848e+01,  2.42159949e+01,  1.94530313e+01,\n",
              "        1.94217284e+01,  1.93804484e+01,  1.93793335e+01,  1.93289529e+01,\n",
              "        1.92866058e+01,  1.92631734e+01,  3.03736200e+00,  2.74941727e+00,\n",
              "        2.90088490e+00,  3.08344497e+00,  2.92721292e+00,  2.67463955e+00,\n",
              "        2.81765761e+00,  1.88109635e+01,  1.89031181e+01,  1.89479913e+01,\n",
              "        1.89901434e+01,  1.89665166e+01,  1.89475656e+01,  1.89266240e+01,\n",
              "        1.77639950e+01,  1.78842658e+01,  1.79654595e+01,  1.80343947e+01,\n",
              "        1.80091324e+01,  1.79876332e+01,  1.79840925e+01, -9.45662089e-01,\n",
              "       -1.20649584e+00, -9.48072854e-01, -7.21613318e-01, -8.80941516e-01,\n",
              "       -1.16865898e+00, -9.81440402e-01,  7.42231382e+00,  6.53014777e+00,\n",
              "        6.23070967e+00,  6.15652095e+00,  5.86466259e+00,  5.51681881e+00,\n",
              "        5.56456052e+00,  4.69312157e+00,  4.38107634e+00,  4.48544006e+00,\n",
              "        4.63057973e+00,  4.47163231e+00,  4.22932670e+00,  4.35026353e+00,\n",
              "        3.40275343e+00,  3.12464452e+00,  3.28495321e+00,  3.45183617e+00,\n",
              "        3.30487831e+00,  3.05950867e+00,  3.20027660e+00,  2.43482936e+01,\n",
              "        2.43899822e+01,  2.43072963e+01,  2.42320712e+01,  2.42133848e+01,\n",
              "        2.42310717e+01,  2.41475100e+01,  2.05303686e+01,  2.05569583e+01,\n",
              "        2.05291078e+01,  2.05226740e+01,  2.04895521e+01,  2.04704608e+01,\n",
              "        2.04292734e+01,  2.59114737e+01,  2.59362912e+01,  2.58158749e+01,\n",
              "        2.57050500e+01,  2.56840093e+01,  2.57123358e+01,  2.56095118e+01,\n",
              "        9.55360027e-01,  3.33669605e-01,  3.48094924e-01,  4.27726300e-01,\n",
              "        2.00995464e-01, -1.43051302e-01,  2.54291693e-03,  2.50604472e+01,\n",
              "        2.49636656e+01,  2.47843070e+01,  2.46530690e+01,  2.45963013e+01,\n",
              "        2.45910531e+01,  2.44883470e+01, -3.43824959e+00, -3.44492501e+00,\n",
              "       -2.96316006e+00, -2.63296388e+00, -2.71625543e+00, -2.96358129e+00,\n",
              "       -2.71954435e+00,  2.67642697e+01,  2.67125234e+01,  2.65330279e+01,\n",
              "        2.63833434e+01,  2.63441958e+01,  2.63634236e+01,  2.62474160e+01,\n",
              "        7.79667719e+00,  6.94759196e+00,  6.66013152e+00,  6.59238143e+00,\n",
              "        6.30385721e+00,  5.96914769e+00,  6.01820662e+00,  6.82632790e+00,\n",
              "        5.62063994e+00,  5.15171058e+00,  4.98127811e+00,  4.60453372e+00,\n",
              "        4.18057833e+00,  4.21885903e+00, -9.24479794e+00, -9.26263950e+00,\n",
              "       -8.63563136e+00, -8.31375267e+00, -8.45190399e+00, -8.76038424e+00,\n",
              "       -8.43081158e+00,  2.58005786e+01,  2.58039169e+01,  2.56714885e+01,\n",
              "        2.55566345e+01,  2.55301565e+01,  2.55529838e+01,  2.54488735e+01,\n",
              "        2.48244588e+01,  2.47083221e+01,  2.45200992e+01,  2.43855635e+01,\n",
              "        2.43237826e+01,  2.43121910e+01,  2.42090035e+01,  2.69581066e+01,\n",
              "        2.69190739e+01,  2.67419333e+01,  2.65899903e+01,  2.65492530e+01,\n",
              "        2.65743572e+01,  2.64579402e+01, -1.29497540e-02, -6.43170664e-01,\n",
              "       -6.13337159e-01, -5.23998470e-01, -7.73689872e-01, -1.13812104e+00,\n",
              "       -9.83253830e-01,  5.70783624e-01,  2.10475503e-01,  3.77426286e-01,\n",
              "        5.57090102e-01,  3.75941274e-01,  7.86438208e-02,  2.40339947e-01,\n",
              "        8.03374599e+00,  7.17732971e+00,  6.88297729e+00,  6.80933832e+00,\n",
              "        6.52269773e+00,  6.18800368e+00,  6.23018373e+00,  2.74904714e+01,\n",
              "        2.74204230e+01,  2.72159792e+01,  2.70436667e+01,  2.69959774e+01,\n",
              "        2.70188802e+01,  2.68959895e+01, -1.32330725e+00, -1.09483676e+00,\n",
              "       -5.23547492e-01, -1.41935164e-01, -1.67200592e-01, -3.41936978e-01,\n",
              "       -1.16360358e-01,  6.95782760e+00,  5.80137825e+00,  5.35688733e+00,\n",
              "        5.20058508e+00,  4.83381335e+00,  4.42051482e+00,  4.45804588e+00,\n",
              "        2.78985700e+01,  2.78533057e+01,  2.76588007e+01,  2.74872688e+01,\n",
              "        2.74482533e+01,  2.74793029e+01,  2.73538051e+01,  1.26214745e+01,\n",
              "        1.25140206e+01,  1.25573132e+01,  1.26458915e+01,  1.25510197e+01,\n",
              "        1.24288858e+01,  1.24720256e+01,  2.74700489e+01,  2.73663444e+01,\n",
              "        2.71421439e+01,  2.69601919e+01,  2.69045795e+01,  2.69191215e+01,\n",
              "        2.67928229e+01,  2.11231772e+01,  2.10570396e+01,  2.09620580e+01,\n",
              "        2.09134410e+01,  2.08600009e+01,  2.08247322e+01,  2.07692781e+01,\n",
              "        3.19400933e+00,  2.73832490e+00,  2.78833576e+00,  2.90801129e+00,\n",
              "        2.70906612e+00,  2.41816802e+00,  2.55121460e+00,  1.19829462e+01,\n",
              "        1.18710366e+01,  1.19252473e+01,  1.20189101e+01,  1.19183791e+01,\n",
              "        1.17886167e+01,  1.18350180e+01,  2.60264842e+01,  2.60242531e+01,\n",
              "        2.58832288e+01,  2.57588043e+01,  2.57247204e+01,  2.57507664e+01,\n",
              "        2.56443578e+01,  4.29497421e+00,  4.25733011e+00,  4.52285807e+00,\n",
              "        4.76563251e+00,  4.67421980e+00,  4.48937272e+00,  4.62944694e+00,\n",
              "        5.24682273e+00,  4.82431427e+00,  4.84398116e+00,  4.94889819e+00,\n",
              "        4.76450328e+00,  4.50042107e+00,  4.60162438e+00,  1.21670240e+01,\n",
              "        1.17289039e+01,  1.15879604e+01,  1.15800309e+01,  1.14003266e+01,\n",
              "        1.11987083e+01,  1.12244794e+01,  4.80425710e+00,  4.86572802e+00,\n",
              "        5.17700933e+00,  5.44217198e+00,  5.37366987e+00,  5.21619079e+00,\n",
              "        5.35324382e+00,  2.79897590e+01,  2.79523446e+01,  2.77613451e+01,\n",
              "        2.75873869e+01,  2.75494834e+01,  2.75818484e+01,  2.74549995e+01,\n",
              "       -1.38523033e+00, -1.50224403e+00, -1.13252845e+00, -8.23316396e-01,\n",
              "       -9.30352665e-01, -1.18415165e+00, -9.73091970e-01, -3.03796037e-02,\n",
              "       -4.07240609e-01, -2.41718912e-01, -5.83663641e-02, -2.47683947e-01,\n",
              "       -5.55219414e-01, -3.85757914e-01,  6.35283047e+00,  5.40725755e+00,\n",
              "        5.09899742e+00,  5.02000027e+00,  4.70793481e+00,  4.33507310e+00,\n",
              "        4.39098950e+00,  2.54647518e+00,  2.88172849e+00,  3.40266419e+00,\n",
              "        3.78747144e+00,  3.78581627e+00,  3.66936540e+00,  3.85496927e+00,\n",
              "        2.20406162e+01,  2.19570569e+01,  2.18351185e+01,  2.17630231e+01,\n",
              "        2.17058410e+01,  2.16740860e+01,  2.16047816e+01,  2.51681266e+01,\n",
              "        2.51076272e+01,  2.49466540e+01,  2.48208534e+01,  2.47769158e+01,\n",
              "        2.47780778e+01,  2.46744708e+01,  1.40449559e+01,  1.41087432e+01,\n",
              "        1.42223124e+01,  1.43388079e+01,  1.42867180e+01,  1.42155790e+01,\n",
              "        1.42483055e+01,  2.26735067e+01,  2.27948695e+01,  2.27837983e+01,\n",
              "        2.27619036e+01,  2.27568334e+01,  2.27767674e+01,  2.27101263e+01,\n",
              "        1.04535655e+01,  1.01510337e+01,  1.01226608e+01,  1.01880905e+01,\n",
              "        1.00424089e+01,  9.85542469e+00,  9.90507621e+00,  8.91446031e+00,\n",
              "        8.54939254e+00,  8.51862495e+00,  8.58465443e+00,  8.41310463e+00,\n",
              "        8.19649043e+00,  8.26101824e+00,  1.34541818e+01,  1.34712112e+01,\n",
              "        1.35761324e+01,  1.36853641e+01,  1.36242275e+01,  1.35373585e+01,\n",
              "        1.35797010e+01,  2.35122998e+01,  2.37676573e+01,  2.38256399e+01,\n",
              "        2.38270312e+01,  2.38595144e+01,  2.39158955e+01,  2.38474264e+01,\n",
              "        2.32202897e+01,  2.32915414e+01,  2.32428737e+01,  2.31955818e+01,\n",
              "        2.31815839e+01,  2.31947345e+01,  2.31188097e+01,  9.37624424e+00,\n",
              "        9.42604806e+00,  9.63868258e+00,  9.82622898e+00,  9.76835160e+00,\n",
              "        9.65084528e+00,  9.74197539e+00,  1.57234797e+01,  1.60552605e+01,\n",
              "        1.62959297e+01,  1.64693066e+01,  1.65002848e+01,  1.65045087e+01,\n",
              "        1.65360057e+01,  2.63382355e+01,  2.62502831e+01,  2.60531460e+01,\n",
              "        2.58973994e+01,  2.58473737e+01,  2.58535244e+01,  2.57352387e+01,\n",
              "        2.36864644e+01,  2.37870909e+01,  2.37495188e+01,  2.37018393e+01,\n",
              "        2.36974774e+01,  2.37220741e+01,  2.36448680e+01, -6.63325243e+00,\n",
              "       -6.82831015e+00, -6.37140487e+00, -6.11090905e+00, -6.27187100e+00,\n",
              "       -6.59566307e+00, -6.31134043e+00,  6.82675930e-01,  1.35450281e-01,\n",
              "        1.85357624e-01,  3.03938432e-01,  7.54691322e-02, -2.64336783e-01,\n",
              "       -1.12093329e-01,  2.27722903e+01,  2.27813039e+01,  2.27020640e+01,\n",
              "        2.26387202e+01,  2.26025453e+01,  2.26004618e+01,  2.25220516e+01,\n",
              "        2.64111391e+01,  2.63629155e+01,  2.61861646e+01,  2.60394180e+01,\n",
              "        2.59947855e+01,  2.60125914e+01,  2.58983181e+01,  4.82227238e+00,\n",
              "        3.91729812e+00,  3.66442488e+00,  3.61746258e+00,  3.30727598e+00,\n",
              "        2.92636332e+00,  3.00449660e+00,  1.89857493e+01,  1.90345068e+01,\n",
              "        1.90476136e+01,  1.90683066e+01,  1.90315618e+01,  1.90022893e+01,\n",
              "        1.89705525e+01,  4.50963933e+00,  3.87837248e+00,  3.80621376e+00,\n",
              "        3.84362344e+00,  3.61391426e+00,  3.29757938e+00,  3.40264277e+00,\n",
              "        1.98106597e+01,  1.97272903e+01,  1.96430976e+01,  1.96105465e+01,\n",
              "        1.95459765e+01,  1.94935698e+01,  1.94473977e+01,  2.59591345e+01,\n",
              "        2.59441410e+01,  2.57971439e+01,  2.56683840e+01,  2.56357554e+01,\n",
              "        2.56542026e+01,  2.55433937e+01,  2.77496827e+01,  2.76785788e+01,\n",
              "        2.74688150e+01,  2.72889037e+01,  2.72425482e+01,  2.72662031e+01,\n",
              "        2.71368595e+01,  6.92894483e+00,  6.59098447e+00,  6.61779084e+00,\n",
              "        6.71890967e+00,  6.55137702e+00,  6.32136797e+00,  6.40557218e+00,\n",
              "        1.25201177e+01,  1.27432199e+01,  1.29842618e+01,  1.31758831e+01,\n",
              "        1.31622675e+01,  1.31121114e+01,  1.31750941e+01,  2.44912450e+01,\n",
              "        2.45265343e+01,  2.44329494e+01,  2.43492330e+01,  2.43277527e+01,\n",
              "        2.43448506e+01,  2.42511431e+01,  8.58010658e+00,  7.87853371e+00,\n",
              "        7.65904825e+00,  7.61953004e+00,  7.36580007e+00,  7.06816587e+00,\n",
              "        7.11321837e+00,  2.71601408e+01,  2.70143716e+01,  2.67684112e+01,\n",
              "        2.65766680e+01,  2.65096533e+01,  2.65113513e+01,  2.63809582e+01,\n",
              "        2.66949781e+01,  2.66225130e+01,  2.64282138e+01,  2.62675345e+01,\n",
              "        2.62209291e+01,  2.62337237e+01,  2.61118367e+01,  7.04986620e+00,\n",
              "        6.15079866e+00,  5.84469109e+00,  5.77009067e+00,  5.46644027e+00,\n",
              "        5.11022188e+00,  5.16216397e+00,  2.67760915e+01,  2.67354810e+01,\n",
              "        2.65575758e+01,  2.64063146e+01,  2.63647426e+01,  2.63865389e+01,\n",
              "        2.62676558e+01,  1.93499851e+01,  1.96250485e+01,  1.97684303e+01,\n",
              "        1.98598250e+01,  1.98892773e+01,  1.99130551e+01,  1.98958491e+01,\n",
              "       -1.54342693e+00, -1.68105705e+00, -1.31474463e+00, -1.03384180e+00,\n",
              "       -1.15010347e+00, -1.40771256e+00, -1.19009884e+00,  6.78349340e+00,\n",
              "        6.62300861e+00,  6.75805425e+00,  6.91902095e+00,  6.79261052e+00,\n",
              "        6.59896046e+00,  6.69729370e+00,  2.66497667e+01,  2.65657511e+01,\n",
              "        2.63637050e+01,  2.62012539e+01,  2.61512169e+01,  2.61620724e+01,\n",
              "        2.60401093e+01,  2.33047337e+01,  2.33030541e+01,  2.32152415e+01,\n",
              "        2.31561641e+01,  2.31342733e+01,  2.31344030e+01,  2.30560031e+01,\n",
              "        8.78269115e-01,  3.51953812e-01,  4.10703401e-01,  5.33496502e-01,\n",
              "        3.05937486e-01, -2.85376180e-02,  1.19522102e-01,  5.93153334e+00,\n",
              "        6.02666334e+00,  6.33280899e+00,  6.58698041e+00,  6.52593072e+00,\n",
              "        6.38320776e+00,  6.51085452e+00,  1.63270388e+00,  1.82864571e+00,\n",
              "        2.29359838e+00,  2.63252733e+00,  2.58612428e+00,  2.42559784e+00,\n",
              "        2.60832449e+00,  2.40097401e+01,  2.38784644e+01,  2.36946680e+01,\n",
              "        2.35690884e+01,  2.35078180e+01,  2.34823598e+01,  2.33837157e+01,\n",
              "        2.58814713e+01,  2.58007362e+01,  2.56129090e+01,  2.54664914e+01,\n",
              "        2.54172837e+01,  2.54212027e+01,  2.53046709e+01,  3.13113907e+00,\n",
              "        3.29341468e+00,  3.69716535e+00,  4.01638219e+00,  3.96505766e+00,\n",
              "        3.81064976e+00,  3.97361314e+00,  1.92896016e+00,  2.22951798e+00,\n",
              "        2.74904245e+00,  3.12561787e+00,  3.10684223e+00,  2.97343034e+00,\n",
              "        3.15941736e+00,  2.79794687e+01,  2.79000390e+01,  2.76818350e+01,\n",
              "        2.74939144e+01,  2.74450102e+01,  2.74682058e+01,  2.73358172e+01,\n",
              "        3.55107732e+00,  3.17900452e+00,  3.26992579e+00,  3.42916237e+00,\n",
              "        3.25438315e+00,  2.98490825e+00,  3.11486225e+00,  2.14478840e+01,\n",
              "        2.14903103e+01,  2.14557801e+01,  2.14365575e+01,  2.14135303e+01,\n",
              "        2.14047822e+01,  2.13458140e+01,  6.88074263e+00,  6.27837640e+00,\n",
              "        6.16126038e+00,  6.19669957e+00,  5.97156559e+00,  5.68284028e+00,\n",
              "        5.75660062e+00,  2.15564369e+01,  2.16034376e+01,  2.15702135e+01,\n",
              "        2.15529945e+01,  2.15342257e+01,  2.15287518e+01,  2.14727625e+01,\n",
              "       -4.51440477e-02,  2.29393934e-01,  7.84260017e-01,  1.17795948e+00,\n",
              "        1.15526427e+00,  1.00142871e+00,  1.21228372e+00,  2.60374540e+01,\n",
              "        2.59870338e+01,  2.58163777e+01,  2.56782733e+01,  2.56366775e+01,\n",
              "        2.56479008e+01,  2.55329629e+01,  2.69921988e+01,  2.68568343e+01,\n",
              "        2.66189313e+01,  2.64339617e+01,  2.63717375e+01,  2.63730726e+01,\n",
              "        2.62430419e+01,  2.06515458e+01,  2.07797377e+01,  2.08092380e+01,\n",
              "        2.08317311e+01,  2.08288716e+01,  2.08318574e+01,  2.07886353e+01])"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_original_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CGpnb1nDMSih",
        "outputId": "04a49eb6-793a-4c3c-c26f-a5758f3f0328"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_temp_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.339122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.061588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.064365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.138175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.996986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>20.809238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>20.831731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>20.828872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>20.831857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>20.788635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>700 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     avg_temp_c\n",
              "0     10.339122\n",
              "1     10.061588\n",
              "2     10.064365\n",
              "3     10.138175\n",
              "4      9.996986\n",
              "..          ...\n",
              "695   20.809238\n",
              "696   20.831731\n",
              "697   20.828872\n",
              "698   20.831857\n",
              "699   20.788635\n",
              "\n",
              "[700 rows x 1 columns]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_original_scale = pd.DataFrame(y_pred_original_scale, columns=['avg_temp_c'])\n",
        "y_pred_original_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "KxX2ZpPsMeVz"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_original_scale.to_csv('y_pred_original_scale.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15cIrnx1xy3K"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "# X, y = load_boston(return_X_y=True)\n",
        "\n",
        "# Split dataset\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('svr', SVR()),\n",
        "    ('dt', DecisionTreeRegressor())\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hohDvtjJyVvC"
      },
      "outputs": [],
      "source": [
        "# Define the Stacking Regressor\n",
        "model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "\n",
        "# Convert PyTorch tensors to NumPy arrays for sklearn\n",
        "# Note: This step assumes X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor are already defined as in your snippet\n",
        "X_train_np = X_train_tensor.cpu().detach().numpy()\n",
        "y_train_np = y_train_tensor.cpu().detach().numpy()\n",
        "X_test_np = X_test_tensor.cpu().detach().numpy()\n",
        "y_test_np = y_test_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L9HlY1Cz61f"
      },
      "outputs": [],
      "source": [
        "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
        "y_train_flattened = y_train.reshape(X_train.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1z7Y_qA1Bco"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "Z7opiCt9z5al",
        "outputId": "a037147b-0292-48c0-cc2e-f60536ca9426"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "y should be a 1d array, got an array of shape (142990, 7) instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e0e87f52cbdb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the Stacking Regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# predictions = model.predict(X_test_np)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[0;32m--> 957\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (142990, 7) instead."
          ]
        }
      ],
      "source": [
        "# Fit the Stacking Regressor\n",
        "model.fit(X_train_flattened, y_train_flattened)\n",
        "\n",
        "# Make predictions\n",
        "# predictions = model.predict(X_test_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "U_9DcfZCW3my",
        "outputId": "52aed658-d4e7-48c8-83b0-3dd54d585318"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.24465196 -1.61516423 -1.18124567 ...  1.64904362  1.58756233\n  1.43095812].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c19b63511285>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Initialize and train the Stacking model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[1;32m    957\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    903\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.24465196 -1.61516423 -1.18124567 ...  1.64904362  1.58756233\n  1.43095812].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "# Initialize and train the Stacking model\n",
        "model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "model.fit(X_train.flatten(), y_train.flatten())\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6KatsZ9xLA4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
